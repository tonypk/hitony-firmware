#include "task_manager.h"
#include "audio_i2s.h"
#include "opus_decoder.h"
#include "opus_encoder.h"
#include "advanced_afe.h"
#include <esp_log.h>
#include <string.h>

static const char* TAG = "audio_tasks";

// 全局AFE实例
static AdvancedAFE* g_afe = nullptr;

// ============================================================================
// Core 1 音频任务
// ============================================================================

/**
 * @brief 音频输入任务 - 从I2S采集音频
 *
 * 优先级: 20 (最高)
 * 核心: Core 1
 * 栈: 8KB
 */
void audio_input_task(void* arg) {
    ESP_LOGI(TAG, "Audio input task started on core %d", xPortGetCoreID());

    AudioI2S& audio = AudioI2S::instance();

    // 输入缓冲区（双麦克风，16bit, 512 samples per channel）
    const size_t frame_samples = 512;
    const size_t frame_bytes = frame_samples * 2 * 2;  // 2 channels, 2 bytes per sample
    uint8_t* input_buf = (uint8_t*)malloc(frame_bytes);

    if (!input_buf) {
        ESP_LOGE(TAG, "Failed to allocate input buffer");
        vTaskDelete(NULL);
        return;
    }

    TickType_t last_wake_time = xTaskGetTickCount();
    const TickType_t frame_period = pdMS_TO_TICKS(32);  // ~32ms per frame

    uint32_t frame_count = 0;
    uint32_t success_count = 0;
    uint32_t fail_count = 0;

    while (1) {
        // 从I2S读取音频
        int n = audio.read_frame(input_buf, frame_bytes);

        if (n > 0) {
            // 分配音频消息
            audio_data_msg_t* msg = alloc_audio_msg(frame_samples, 2);
            if (msg) {
                // 拷贝数据
                memcpy(msg->data, input_buf, n);

                // 发送到AFE队列（如果队列满则丢弃）
                if (xQueueSend(g_audio_input_queue, &msg, 0) == pdTRUE) {
                    success_count++;
                } else {
                    ESP_LOGW(TAG, "Audio input queue full, dropping frame");
                    free_audio_msg(msg);
                    fail_count++;
                }
            }
        }

        frame_count++;
        // 每5秒（约156帧）打印一次统计
        if (frame_count % 156 == 0) {
            ESP_LOGI(TAG, "Audio stats: read=%lu, success=%lu, dropped=%lu",
                     frame_count, success_count, fail_count);
        }

        // 保持固定帧率
        vTaskDelayUntil(&last_wake_time, frame_period);
    }

    free(input_buf);
    vTaskDelete(NULL);
}

/**
 * @brief 音频输出任务 - 播放音频到I2S
 *
 * 优先级: 19
 * 核心: Core 1
 * 栈: 8KB
 */
void audio_output_task(void* arg) {
    ESP_LOGI(TAG, "Audio output task started on core %d", xPortGetCoreID());

    AudioI2S& audio = AudioI2S::instance();

    while (1) {
        audio_data_msg_t* msg = nullptr;

        // 从输出队列获取音频（阻塞等待）
        if (xQueueReceive(g_audio_output_queue, &msg, portMAX_DELAY) == pdTRUE) {
            if (msg && msg->data) {
                // 播放音频
                size_t bytes = msg->samples * msg->channels * sizeof(int16_t);
                int ret = audio.play_frame((uint8_t*)msg->data, bytes);

                if (ret < 0) {
                    ESP_LOGE(TAG, "Failed to play audio frame");
                }
            }

            // 释放消息
            free_audio_msg(msg);
        }
    }

    vTaskDelete(NULL);
}

/**
 * @brief AFE处理任务 - 音频前端处理
 *
 * 优先级: 18
 * 核心: Core 1
 * 栈: 16KB
 *
 * TODO: 集成ESP-SR的AFE算法
 */
void afe_process_task(void* arg) {
    ESP_LOGI(TAG, "AFE process task started on core %d", xPortGetCoreID());

    uint32_t frame_count = 0;
    uint32_t fed_frames = 0;
    uint32_t encode_sent = 0;
    uint32_t encode_dropped = 0;

    while (1) {
        audio_data_msg_t* msg = nullptr;

        // 从输入队列获取原始双声道音频
        if (xQueueReceive(g_audio_input_queue, &msg, portMAX_DELAY) == pdTRUE) {
            if (msg && msg->data) {
                frame_count++;

                // 喂入Advanced AFE进行处理
                // AFE会自动进行：AEC, NS, AGC, Beamforming, VAD, 唤醒词检测
                // AFE的输出会直接发送到g_afe_output_queue给wake_detect_task处理
                if (g_afe) {
                    g_afe->feed(msg->data, msg->samples);
                    fed_frames++;

                    // 如果在录音状态，也需要将AFE输出发送到编码队列
                    // 这需要从g_afe_output_queue读取数据并复制到编码队列
                    // TODO: 优化录音时的数据流
                }

                // 每5秒打印一次统计
                if (frame_count % 156 == 0) {
                    int energy = g_afe ? g_afe->get_audio_energy() : 0;
                    bool vad = g_afe ? g_afe->is_voice_active() : false;
                    ESP_LOGI(TAG, "AFE stats: in=%lu, fed=%lu, encoded=%lu (drop=%lu), energy=%d, vad=%d",
                             frame_count, fed_frames, encode_sent, encode_dropped,
                             energy, vad);
                }
            }

            free_audio_msg(msg);
        }
    }

    vTaskDelete(NULL);
}

/**
 * @brief 唤醒词检测任务
 *
 * 优先级: 16
 * 核心: Core 1
 * 栈: 12KB
 *
 * TODO: 集成ESP-SR的WakeNet
 */
void wake_detect_task(void* arg) {
    ESP_LOGI(TAG, "Wake detect task started on core %d", xPortGetCoreID());

    // TODO: 初始化ESP-SR WakeNet模型
    // - 加载唤醒词模型
    // - 配置检测参数

    uint32_t frame_count = 0;
    uint32_t wake_detected_count = 0;

    while (1) {
        audio_data_msg_t* msg = nullptr;

        // 从AFE输出队列获取处理后的音频
        if (xQueueReceive(g_afe_output_queue, &msg, portMAX_DELAY) == pdTRUE) {
            if (msg && msg->data) {
                frame_count++;

                // TODO: 唤醒词检测
                // - 将音频送入WakeNet
                // - 检测是否包含唤醒词
                // - 如果检测到，发送唤醒事件

                // 临时禁用唤醒词触发，避免崩溃
                // TODO: 修复内存问题后重新启用
                // if (frame_count % 100 == 0) { ... }

                // 临时禁用录音数据转发
                // TODO: 修复内存问题后重新启用
                // EventBits_t bits = xEventGroupGetBits(g_app_event_group);
                // if (bits & EVENT_RECORDING_START) { ... }

                // 每5秒打印一次统计
                if (frame_count % 156 == 0) {
                    ESP_LOGI(TAG, "Wake stats: frames=%lu, detected=%lu",
                             frame_count, wake_detected_count);
                }
            }

            // 释放音频消息
            free_audio_msg(msg);
        }
    }

    vTaskDelete(NULL);
}

/**
 * @brief 音频混音任务
 *
 * 优先级: 15
 * 核心: Core 1
 * 栈: 8KB
 */
void audio_mixer_task(void* arg) {
    ESP_LOGI(TAG, "Audio mixer task started on core %d", xPortGetCoreID());

    while (1) {
        audio_data_msg_t* msg = nullptr;

        // 从解码队列获取PCM音频
        if (xQueueReceive(g_audio_decode_queue, &msg, portMAX_DELAY) == pdTRUE) {
            if (msg && msg->data) {
                // TODO: 音频处理
                // - 音量控制
                // - 淡入淡出
                // - 提示音混合

                // 暂时直接转发到输出队列
                if (xQueueSend(g_audio_output_queue, &msg, pdMS_TO_TICKS(100)) != pdTRUE) {
                    ESP_LOGW(TAG, "Output queue full, dropping frame");
                    free_audio_msg(msg);
                }
            } else {
                free_audio_msg(msg);
            }
        }
    }

    vTaskDelete(NULL);
}

/**
 * @brief Opus解码任务
 *
 * 优先级: 14
 * 核心: Core 1
 * 栈: 16KB
 */
void opus_decode_task(void* arg) {
    ESP_LOGI(TAG, "Opus decode task started on core %d", xPortGetCoreID());

    // 初始化Opus解码器
    OpusDecoder decoder;
    if (!decoder.init(16000, 1)) {
        ESP_LOGE(TAG, "Failed to initialize Opus decoder");
        vTaskDelete(NULL);
        return;
    }

    ESP_LOGI(TAG, "Opus decoder initialized (16kHz, mono)");

    while (1) {
        opus_packet_msg_t* msg = nullptr;

        // 从WebSocket接收队列获取Opus包
        if (xQueueReceive(g_ws_rx_queue, &msg, portMAX_DELAY) == pdTRUE) {
            if (msg && msg->data && msg->len > 0) {
                // 解码Opus包
                int16_t pcm[960];  // 60ms @ 16kHz = 960 samples
                int samples = decoder.decode(msg->data, msg->len, pcm, 960);

                if (samples > 0) {
                    // 分配音频消息
                    audio_data_msg_t* audio_msg = alloc_audio_msg(samples, 1);
                    if (audio_msg) {
                        memcpy(audio_msg->data, pcm, samples * sizeof(int16_t));

                        // 发送到混音队列
                        if (xQueueSend(g_audio_decode_queue, &audio_msg, pdMS_TO_TICKS(100)) != pdTRUE) {
                            ESP_LOGW(TAG, "Decode queue full, dropping frame");
                            free_audio_msg(audio_msg);
                        }
                    }
                } else {
                    ESP_LOGE(TAG, "Opus decode failed");
                }
            }

            // 释放Opus包
            free_opus_msg(msg);
        }
    }

    vTaskDelete(NULL);
}

/**
 * @brief Opus编码任务
 *
 * 优先级: 13
 * 核心: Core 1
 * 栈: 16KB
 */
void opus_encode_task(void* arg) {
    ESP_LOGI(TAG, "Opus encode task started on core %d", xPortGetCoreID());

    // 初始化Opus编码器 (16kHz, mono, 24kbps)
    OpusEncoder encoder;
    if (!encoder.init(16000, 1, 24000)) {
        ESP_LOGE(TAG, "Failed to initialize Opus encoder");
        vTaskDelete(NULL);
        return;
    }

    ESP_LOGI(TAG, "Opus encoder initialized (16kHz, mono, 24kbps, frame=%zu samples)",
             encoder.frame_size());

    // 累积缓冲区（用于累积到一个完整的Opus帧）
    const size_t opus_frame_size = encoder.frame_size();  // 960 samples @ 16kHz 60ms
    int16_t* accum_buf = (int16_t*)malloc(opus_frame_size * sizeof(int16_t));
    if (!accum_buf) {
        ESP_LOGE(TAG, "Failed to allocate accumulation buffer");
        vTaskDelete(NULL);
        return;
    }

    size_t accum_samples = 0;
    uint32_t frame_count = 0;
    uint32_t encoded_count = 0;
    uint32_t dropped_count = 0;

    while (1) {
        audio_data_msg_t* msg = nullptr;

        // 从编码队列获取PCM音频（录音数据）
        if (xQueueReceive(g_audio_encode_queue, &msg, portMAX_DELAY) == pdTRUE) {
            if (msg && msg->data) {
                frame_count++;

                // 将音频数据累积到缓冲区
                size_t samples_to_copy = msg->samples;
                size_t space_left = opus_frame_size - accum_samples;

                if (samples_to_copy > space_left) {
                    samples_to_copy = space_left;
                }

                memcpy(&accum_buf[accum_samples], msg->data, samples_to_copy * sizeof(int16_t));
                accum_samples += samples_to_copy;

                // 如果累积了一个完整的Opus帧，进行编码
                if (accum_samples >= opus_frame_size) {
                    uint8_t opus_data[512];  // Opus包最大长度
                    int opus_len = encoder.encode(accum_buf, opus_frame_size, opus_data, sizeof(opus_data));

                    if (opus_len > 0) {
                        // 分配Opus包消息
                        opus_packet_msg_t* opus_msg = alloc_opus_msg(opus_len);
                        if (opus_msg) {
                            memcpy(opus_msg->data, opus_data, opus_len);

                            // 发送到WebSocket发送队列
                            if (xQueueSend(g_ws_tx_queue, &opus_msg, pdMS_TO_TICKS(100)) == pdTRUE) {
                                encoded_count++;
                            } else {
                                ESP_LOGW(TAG, "WebSocket TX queue full, dropping packet");
                                free_opus_msg(opus_msg);
                                dropped_count++;
                            }
                        }
                    } else {
                        ESP_LOGE(TAG, "Opus encode failed");
                    }

                    // 重置累积计数
                    accum_samples = 0;
                }

                // 每10个帧打印一次统计
                if (frame_count % 10 == 0) {
                    ESP_LOGI(TAG, "Encode stats: in=%lu, encoded=%lu, dropped=%lu, accum=%zu/%zu",
                             frame_count, encoded_count, dropped_count, accum_samples, opus_frame_size);
                }
            }

            free_audio_msg(msg);
        }
    }

    free(accum_buf);
    vTaskDelete(NULL);
}

// ============================================================================
// AFE初始化和回调
// ============================================================================

// ============================================================================
// AFE初始化和回调
// ============================================================================

/**
 * @brief 唤醒词检测回调
 */
static void on_wake_word_detected(const char* wake_word) {
    ESP_LOGI(TAG, "=== WAKE WORD DETECTED: %s ===", wake_word);

    // 发送唤醒事件到状态机
    state_event_msg_t event = {};
    event.type = STATE_EVENT_WAKE_DETECTED;
    if (wake_word) {
        strncpy(event.data.wake.wake_word, wake_word, sizeof(event.data.wake.wake_word) - 1);
    }
    send_state_event(event);
}

/**
 * @brief VAD状态变化回调
 */
static void on_vad_state_changed(bool voice_active) {
    ESP_LOGD(TAG, "VAD state changed: %s", voice_active ? "ACTIVE" : "INACTIVE");
}

/**
 * @brief 初始化先进的AFE系统
 */
bool init_advanced_afe() {
    ESP_LOGI(TAG, "Initializing Advanced AFE...");

    g_afe = new AdvancedAFE();
    if (!g_afe) {
        ESP_LOGE(TAG, "Failed to allocate AFE");
        return false;
    }

    // 配置AFE
    AdvancedAFE::Config config;
    config.sample_rate = 16000;
    config.channels = 2;
    config.frame_size = 512;

    config.enable_aec = false;
    config.enable_ns = true;
    config.enable_agc = true;
    config.enable_vad = true;
    config.enable_wakenet = false;  // 暂时禁用，模型文件导致崩溃

    config.agc_level = 3;
    config.ns_level = 2;
    config.wake_threshold = 0;

    if (!g_afe->init(config)) {
        ESP_LOGE(TAG, "Failed to initialize AFE");
        delete g_afe;
        g_afe = nullptr;
        return false;
    }

    g_afe->on_wake_detected(on_wake_word_detected);
    g_afe->on_vad_changed(on_vad_state_changed);

    if (!g_afe->start()) {
        ESP_LOGE(TAG, "Failed to start AFE task");
        delete g_afe;
        g_afe = nullptr;
        return false;
    }

    ESP_LOGI(TAG, "Advanced AFE initialized successfully");
    return true;
}
